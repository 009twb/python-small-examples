{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Movie ID                                        Movie Title  \\\n",
      "0         8      Edison Kinetoscopic Record of a Sneeze (1894)   \n",
      "1        10                La sortie des usines Lumi猫re (1895)   \n",
      "2        12                      The Arrival of a Train (1896)   \n",
      "3        25  The Oxford and Cambridge University Boat Race ...   \n",
      "4        91                         Le manoir du diable (1896)   \n",
      "5       131                           Une nuit terrible (1896)   \n",
      "6       417                      Le voyage dans la lune (1902)   \n",
      "7       439                     The Great Train Robbery (1903)   \n",
      "8       443        Hiawatha, the Messiah of the Ojibway (1903)   \n",
      "9       628                    The Adventures of Dollie (1908)   \n",
      "\n",
      "                                          Genre  \n",
      "0                             Documentary|Short  \n",
      "1                             Documentary|Short  \n",
      "2                             Documentary|Short  \n",
      "3                                           NaN  \n",
      "4                                  Short|Horror  \n",
      "5                           Short|Comedy|Horror  \n",
      "6  Short|Action|Adventure|Comedy|Fantasy|Sci-Fi  \n",
      "7                    Short|Action|Crime|Western  \n",
      "8                                           NaN  \n",
      "9                                  Action|Short  \n",
      "   User ID  Twitter ID\n",
      "0        1   397291295\n",
      "1        2    40501255\n",
      "2        3   417333257\n",
      "3        4   138805259\n",
      "4        5  2452094989\n",
      "5        6   391774225\n",
      "6        7    47317010\n",
      "7        8    84541461\n",
      "8        9  2445803544\n",
      "9       10   995885060\n",
      "   User ID  Movie ID  Rating  Rating Timestamp\n",
      "0        1    111161      10        1373234211\n",
      "1        1    117060       7        1373415231\n",
      "2        1    120755       6        1373424360\n",
      "3        1    317919       6        1373495763\n",
      "4        1    454876      10        1373621125\n",
      "5        1    790724       8        1374641320\n",
      "6        1    882977       8        1372898763\n",
      "7        1   1229238       9        1373506523\n",
      "8        1   1288558       5        1373154354\n",
      "9        1   1300854       8        1377165712\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "movies = pd.read_csv('./data/movietweetings/movies.dat', delimiter='::',\n",
    "                     engine='python', header=None, names=['Movie ID', 'Movie Title', 'Genre'])\n",
    "print(movies.head(10))\n",
    "users = pd.read_csv('./data/movietweetings/users.dat', delimiter='::',\n",
    "                    engine='python', header=None, names=['User ID', 'Twitter ID'])\n",
    "print(users.head(10))\n",
    "ratings = pd.read_csv('./data/movietweetings/ratings.dat', delimiter='::', engine='python',\n",
    "                      header=None, names=['User ID', 'Movie ID', 'Rating', 'Rating Timestamp'])\n",
    "\n",
    "print(ratings.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie ID</th>\n",
       "      <th>Movie Title</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8419</th>\n",
       "      <td>111161</td>\n",
       "      <td>The Shawshank Redemption (1994)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Movie ID                      Movie Title  Genre\n",
       "8419    111161  The Shawshank Redemption (1994)  Drama"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies[movies['Movie ID']==111161]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 找出喜剧(comedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5     True\n",
      "6     True\n",
      "7    False\n",
      "8    False\n",
      "9    False\n",
      "Name: Genre, dtype: bool\n",
      "5      131\n",
      "6      417\n",
      "15    2354\n",
      "18    3863\n",
      "19    4099\n",
      "20    4100\n",
      "21    4101\n",
      "22    4210\n",
      "23    4395\n",
      "25    4518\n",
      "Name: Movie ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mask = movies.Genre.str.contains('comedy', case=False, na=False)\n",
    "print(mask.head(10))\n",
    "comedy = movies[mask]\n",
    "comedy_ids = comedy['Movie ID']\n",
    "print(comedy_ids.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 关联rating表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User ID  Movie ID  Rating  Rating Timestamp  Movie ID2 Movie Title Genre\n",
      "0        1    111161      10        1373234211        NaN         NaN   NaN\n",
      "1        1    117060       7        1373415231        NaN         NaN   NaN\n",
      "2        1    120755       6        1373424360        NaN         NaN   NaN\n",
      "3        1    317919       6        1373495763        NaN         NaN   NaN\n",
      "4        1    454876      10        1373621125        NaN         NaN   NaN\n",
      "5        1    790724       8        1374641320        NaN         NaN   NaN\n",
      "6        1    882977       8        1372898763        NaN         NaN   NaN\n",
      "7        1   1229238       9        1373506523        NaN         NaN   NaN\n",
      "8        1   1288558       5        1373154354        NaN         NaN   NaN\n",
      "9        1   1300854       8        1377165712        NaN         NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "combine = ratings.join(comedy, on='Movie ID', rsuffix='2') ### BUG BUG BUG!!!!!!\n",
    "print(combine.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      User ID  Movie ID  Rating  Rating Timestamp  Movie ID2  \\\n",
      "347        53     31381       9        1362133907  5745450.0   \n",
      "593        69     33467       8        1440456538  7671064.0   \n",
      "3297      188     22279       8        1365438569  2140577.0   \n",
      "3599      228     33467       7        1537651137  7671064.0   \n",
      "4392      288     21749      10        1435980991  2061861.0   \n",
      "6047      501     31381       8        1381784126  5745450.0   \n",
      "6354      518     31381      10        1391099884  5745450.0   \n",
      "6409      520       417      10        1437579236    24852.0   \n",
      "6413      520     22100       9        1474939689  2112096.0   \n",
      "6415      520     23634       9        1460240847  2380331.0   \n",
      "\n",
      "                                  Movie Title                          Genre  \n",
      "347                               Chef (2017)            Comedy|Drama|Family  \n",
      "593           Brittany Runs A Marathon (2019)                   Comedy|Drama  \n",
      "3297                    The Pretty One (2013)                   Comedy|Drama  \n",
      "3599          Brittany Runs A Marathon (2019)                   Comedy|Drama  \n",
      "4392  You Really Fucked Me Back There. (2011)             Short|Comedy|Drama  \n",
      "6047                              Chef (2017)            Comedy|Drama|Family  \n",
      "6354                              Chef (2017)            Comedy|Drama|Family  \n",
      "6409                  Babes in Toyland (1934)  Comedy|Family|Fantasy|Musical  \n",
      "6413    Absolutely Fabulous: The Movie (2016)                   Comedy|Crime  \n",
      "6415                Words and Pictures (2013)           Comedy|Drama|Romance  \n"
     ]
    }
   ],
   "source": [
    "result = combine[pd.notnull(combine['Movie ID2'])]\n",
    "print(result.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么Movie ID2的类型变了？检查下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User ID               int64\n",
       "Movie ID              int64\n",
       "Rating                int64\n",
       "Rating Timestamp      int64\n",
       "Movie ID2           float64\n",
       "Movie Title          object\n",
       "Genre                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method join in module pandas.core.frame:\n",
      "\n",
      "join(other, on=None, how='left', lsuffix='', rsuffix='', sort=False) method of pandas.core.frame.DataFrame instance\n",
      "    Join columns with other DataFrame either on index or on a key\n",
      "    column. Efficiently Join multiple DataFrame objects by index at once by\n",
      "    passing a list.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    other : DataFrame, Series with name field set, or list of DataFrame\n",
      "        Index should be similar to one of the columns in this one. If a\n",
      "        Series is passed, its name attribute must be set, and that will be\n",
      "        used as the column name in the resulting joined DataFrame\n",
      "    on : column name, tuple/list of column names, or array-like\n",
      "        Column(s) in the caller to join on the index in other,\n",
      "        otherwise joins index-on-index. If multiples\n",
      "        columns given, the passed DataFrame must have a MultiIndex. Can\n",
      "        pass an array as the join key if not already contained in the\n",
      "        calling DataFrame. Like an Excel VLOOKUP operation\n",
      "    how : {'left', 'right', 'outer', 'inner'}, default: 'left'\n",
      "        How to handle the operation of the two objects.\n",
      "    \n",
      "        * left: use calling frame's index (or column if on is specified)\n",
      "        * right: use other frame's index\n",
      "        * outer: form union of calling frame's index (or column if on is\n",
      "          specified) with other frame's index, and sort it\n",
      "          lexicographically\n",
      "        * inner: form intersection of calling frame's index (or column if\n",
      "          on is specified) with other frame's index, preserving the order\n",
      "          of the calling's one\n",
      "    lsuffix : string\n",
      "        Suffix to use from left frame's overlapping columns\n",
      "    rsuffix : string\n",
      "        Suffix to use from right frame's overlapping columns\n",
      "    sort : boolean, default False\n",
      "        Order result DataFrame lexicographically by the join key. If False,\n",
      "        the order of the join key depends on the join type (how keyword)\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    on, lsuffix, and rsuffix options are not supported when passing a list\n",
      "    of DataFrame objects\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> caller = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n",
      "    ...                        'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
      "    \n",
      "    >>> caller\n",
      "        A key\n",
      "    0  A0  K0\n",
      "    1  A1  K1\n",
      "    2  A2  K2\n",
      "    3  A3  K3\n",
      "    4  A4  K4\n",
      "    5  A5  K5\n",
      "    \n",
      "    >>> other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],\n",
      "    ...                       'B': ['B0', 'B1', 'B2']})\n",
      "    \n",
      "    >>> other\n",
      "        B key\n",
      "    0  B0  K0\n",
      "    1  B1  K1\n",
      "    2  B2  K2\n",
      "    \n",
      "    Join DataFrames using their indexes.\n",
      "    \n",
      "    >>> caller.join(other, lsuffix='_caller', rsuffix='_other')\n",
      "    \n",
      "    >>>     A key_caller    B key_other\n",
      "        0  A0         K0   B0        K0\n",
      "        1  A1         K1   B1        K1\n",
      "        2  A2         K2   B2        K2\n",
      "        3  A3         K3  NaN       NaN\n",
      "        4  A4         K4  NaN       NaN\n",
      "        5  A5         K5  NaN       NaN\n",
      "    \n",
      "    \n",
      "    If we want to join using the key columns, we need to set key to be\n",
      "    the index in both caller and other. The joined DataFrame will have\n",
      "    key as its index.\n",
      "    \n",
      "    >>> caller.set_index('key').join(other.set_index('key'))\n",
      "    \n",
      "    >>>      A    B\n",
      "        key\n",
      "        K0   A0   B0\n",
      "        K1   A1   B1\n",
      "        K2   A2   B2\n",
      "        K3   A3  NaN\n",
      "        K4   A4  NaN\n",
      "        K5   A5  NaN\n",
      "    \n",
      "    Another option to join using the key columns is to use the on\n",
      "    parameter. DataFrame.join always uses other's index but we can use any\n",
      "    column in the caller. This method preserves the original caller's\n",
      "    index in the result.\n",
      "    \n",
      "    >>> caller.join(other.set_index('key'), on='key')\n",
      "    \n",
      "    >>>     A key    B\n",
      "        0  A0  K0   B0\n",
      "        1  A1  K1   B1\n",
      "        2  A2  K2   B2\n",
      "        3  A3  K3  NaN\n",
      "        4  A4  K4  NaN\n",
      "        5  A5  K5  NaN\n",
      "    \n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    DataFrame.merge : For column(s)-on-columns(s) operations\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    joined : DataFrame\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ratings.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Movie ID              Movie Title                          Genre\n",
      "417     24852  Babes in Toyland (1934)  Comedy|Family|Fantasy|Musical\n"
     ]
    }
   ],
   "source": [
    "print(comedy[comedy['Movie ID']==24852])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出现一个坑：\n",
    "\n",
    "join链接时，ratings表Movie ID 字段与 comedy表Index建立关系\n",
    "\n",
    "大坑！\n",
    "改\n",
    "\n",
    "以上是官档中一句话：\n",
    "\n",
    "DataFrame.join always uses other’s index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User ID  Movie ID  Rating  Rating Timestamp Movie Title Genre\n",
      "0        1    111161      10        1373234211         NaN   NaN\n",
      "1        1    117060       7        1373415231         NaN   NaN\n",
      "2        1    120755       6        1373424360         NaN   NaN\n",
      "3        1    317919       6        1373495763         NaN   NaN\n",
      "4        1    454876      10        1373621125         NaN   NaN\n",
      "5        1    790724       8        1374641320         NaN   NaN\n",
      "6        1    882977       8        1372898763         NaN   NaN\n",
      "7        1   1229238       9        1373506523         NaN   NaN\n",
      "8        1   1288558       5        1373154354         NaN   NaN\n",
      "9        1   1300854       8        1377165712         NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "combine = ratings.join(comedy.set_index('Movie ID'), on='Movie ID')\n",
    "print(combine.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    User ID  Movie ID  Rating  Rating Timestamp              Movie Title  \\\n",
      "12        1   1588173       9        1372821281       Warm Bodies (2013)   \n",
      "13        1   1711425       3        1372604878         21 & Over (2013)   \n",
      "14        1   2024432       8        1372703553    Identity Thief (2013)   \n",
      "17        1   2101441       1        1372633473   Spring Breakers (2012)   \n",
      "28        2   1431045       7        1457733508          Deadpool (2016)   \n",
      "32        2   1675434       8        1396688981  The Intouchables (2011)   \n",
      "36        2   2294629       8        1392455710            Frozen (2013)   \n",
      "37        2   2361509       8        1446837136        The Intern (2015)   \n",
      "40        2   2883512       8        1432407808              Chef (2014)   \n",
      "41        2   3079380       8        1433614454               Spy (2015)   \n",
      "\n",
      "                                                Genre  \n",
      "12                              Comedy|Horror|Romance  \n",
      "13                                             Comedy  \n",
      "14                       Adventure|Comedy|Crime|Drama  \n",
      "17                                 Comedy|Crime|Drama  \n",
      "28                     Action|Adventure|Comedy|Sci-Fi  \n",
      "32                             Biography|Comedy|Drama  \n",
      "36  Animation|Adventure|Comedy|Family|Fantasy|Musical  \n",
      "37                                       Comedy|Drama  \n",
      "40                             Adventure|Comedy|Drama  \n",
      "41                                Action|Comedy|Crime  \n"
     ]
    }
   ],
   "source": [
    "result = combine[pd.notnull(combine['Genre'])]\n",
    "print(result.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再演证下\n",
    "\n",
    "拿Movie ID 1588173 到 comdey表中查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie ID</th>\n",
       "      <th>Movie Title</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19131</th>\n",
       "      <td>1588173</td>\n",
       "      <td>Warm Bodies (2013)</td>\n",
       "      <td>Comedy|Horror|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Movie ID         Movie Title                  Genre\n",
       "19131   1588173  Warm Bodies (2013)  Comedy|Horror|Romance"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comedy[comedy['Movie ID']==1588173]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到comedy表中Movie ID 与 ratings表 中一致\n",
    "\n",
    "验证通过！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 按照Movie ID 分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_as_movie = result.groupby('Movie ID').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User ID             float64\n",
       "Rating              float64\n",
       "Rating Timestamp    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_as_movie.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               User ID  Rating  Rating Timestamp\n",
      "Movie ID                                        \n",
      "131       34861.000000     7.0      1.540639e+09\n",
      "417       34121.409091     8.5      1.458680e+09\n",
      "2354       6264.000000     8.0      1.456343e+09\n",
      "3863      43803.000000    10.0      1.430439e+09\n",
      "4099      25084.500000     7.0      1.450323e+09\n"
     ]
    }
   ],
   "source": [
    "print(score_as_movie.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mv417 = ratings[ratings['Movie ID']==417]\n",
    "print(mv417)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.5"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv417['Rating'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 按照电影得分排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-06c7f2d85ace>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_as_movie\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Rating'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "sorted(score_as_movie,key='Rating',reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function sorted in module builtins:\n",
      "\n",
      "sorted(iterable, /, *, key=None, reverse=False)\n",
      "    Return a new list containing all items from the iterable in ascending order.\n",
      "    \n",
      "    A custom key function can be supplied to customize the sort order, and the\n",
      "    reverse flag can be set to request the result in descending order.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Iterable\n",
    "isinstance(score_as_movie,Iterable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还是用pandas提供的sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_as_movie.sort_values(by='Rating', ascending = False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bests = score_as_movie[score_as_movie['Rating']==10.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10740"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(score_as_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method sort_values in module pandas.core.frame:\n",
      "\n",
      "sort_values(by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last') method of pandas.core.frame.DataFrame instance\n",
      "    Sort by the values along either axis\n",
      "    \n",
      "    .. versionadded:: 0.17.0\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    by : str or list of str\n",
      "        Name or list of names which refer to the axis items.\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        Axis to direct sorting\n",
      "    ascending : bool or list of bool, default True\n",
      "         Sort ascending vs. descending. Specify list for multiple sort\n",
      "         orders.  If this is a list of bools, must match the length of\n",
      "         the by.\n",
      "    inplace : bool, default False\n",
      "         if True, perform operation in-place\n",
      "    kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      "         Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      "         information.  `mergesort` is the only stable algorithm. For\n",
      "         DataFrames, this option is only applied when sorting on a single\n",
      "         column or label.\n",
      "    na_position : {'first', 'last'}, default 'last'\n",
      "         `first` puts NaNs at the beginning, `last` puts NaNs at the end\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    sorted_obj : DataFrame\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(score_as_movie.sort_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 电影观看人数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DataFrameGroupBy in module pandas.core.groupby object:\n",
      "\n",
      "class DataFrameGroupBy(NDFrameGroupBy)\n",
      " |  Class for grouping and aggregating relational data. See aggregate,\n",
      " |  transform, and apply functions on this object.\n",
      " |  \n",
      " |  It's easiest to use obj.groupby(...) to use GroupBy, but you can also do:\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      grouped = groupby(obj, ...)\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  obj : pandas object\n",
      " |  axis : int, default 0\n",
      " |  level : int, default None\n",
      " |      Level of MultiIndex\n",
      " |  groupings : list of Grouping objects\n",
      " |      Most users should ignore this\n",
      " |  exclusions : array-like, optional\n",
      " |      List of columns to exclude\n",
      " |  name : string\n",
      " |      Most users should ignore this\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  After grouping, see aggregate, apply, and transform functions. Here are\n",
      " |  some other brief notes about usage. When grouping by multiple groups, the\n",
      " |  result index will be a MultiIndex (hierarchical) by default.\n",
      " |  \n",
      " |  Iteration produces (key, group) tuples, i.e. chunking the data by group. So\n",
      " |  you can write code like:\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      grouped = obj.groupby(keys, axis=axis)\n",
      " |      for key, group in grouped:\n",
      " |          # do something with the data\n",
      " |  \n",
      " |  Function calls on GroupBy, if not specially implemented, \"dispatch\" to the\n",
      " |  grouped data. So if you group a DataFrame and wish to invoke the std()\n",
      " |  method on each group, you can simply do:\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      df.groupby(mapper).std()\n",
      " |  \n",
      " |  rather than\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      df.groupby(mapper).aggregate(np.std)\n",
      " |  \n",
      " |  You can pass arguments to these \"wrapped\" functions, too.\n",
      " |  \n",
      " |  See the online documentation for full exposition on these topics and much\n",
      " |  more\n",
      " |  \n",
      " |  Returns\n",
      " |  -------\n",
      " |  **Attributes**\n",
      " |  groups : dict\n",
      " |      {group name -> group labels}\n",
      " |  len(grouped) : int\n",
      " |      Number of groups\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataFrameGroupBy\n",
      " |      NDFrameGroupBy\n",
      " |      GroupBy\n",
      " |      _GroupBy\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.base.StringMixin\n",
      " |      pandas.core.base.SelectionMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  agg = aggregate(self, arg, *args, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, arg, *args, **kwargs)\n",
      " |      Aggregate using callable, string, dict, or list of string/callables\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable, string, dictionary, or list of string/callables\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply. For\n",
      " |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      " |      \n",
      " |          Accepted Combinations are:\n",
      " |      \n",
      " |          - string function name\n",
      " |          - function\n",
      " |          - list of functions\n",
      " |          - dict of column names -> functions (or list of functions)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Numpy functions mean/median/prod/sum/std/var are special cased so the\n",
      " |      default behavior is applying the function along axis=0\n",
      " |      (e.g., np.mean(arr_2d, axis=0)) as opposed to\n",
      " |      mimicking the default Numpy behavior (e.g., np.mean(arr_2d)).\n",
      " |      \n",
      " |      agg is an alias for aggregate. Use it.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      aggregated : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 2],\n",
      " |      ...                    'B': [1, 2, 3, 4],\n",
      " |      ...                    'C': np.random.randn(4)})\n",
      " |      \n",
      " |      >>> df\n",
      " |         A  B         C\n",
      " |      0  1  1  0.362838\n",
      " |      1  1  2  0.227877\n",
      " |      2  2  3  1.267767\n",
      " |      3  2  4 -0.562860\n",
      " |      \n",
      " |      The aggregation is for each column.\n",
      " |      \n",
      " |      >>> df.groupby('A').agg('min')\n",
      " |         B         C\n",
      " |      A\n",
      " |      1  1  0.227877\n",
      " |      2  3 -0.562860\n",
      " |      \n",
      " |      Multiple aggregations\n",
      " |      \n",
      " |      >>> df.groupby('A').agg(['min', 'max'])\n",
      " |          B             C\n",
      " |        min max       min       max\n",
      " |      A\n",
      " |      1   1   2  0.227877  0.362838\n",
      " |      2   3   4 -0.562860  1.267767\n",
      " |      \n",
      " |      Select a column for aggregation\n",
      " |      \n",
      " |      >>> df.groupby('A').B.agg(['min', 'max'])\n",
      " |         min  max\n",
      " |      A\n",
      " |      1    1    2\n",
      " |      2    3    4\n",
      " |      \n",
      " |      Different aggregations per column\n",
      " |      \n",
      " |      >>> df.groupby('A').agg({'B': ['min', 'max'], 'C': 'sum'})\n",
      " |          B             C\n",
      " |        min max       sum\n",
      " |      A\n",
      " |      1   1   2  0.590716\n",
      " |      2   3   4  0.704907\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.DataFrame.groupby.apply\n",
      " |      pandas.DataFrame.groupby.transform\n",
      " |      pandas.DataFrame.aggregate\n",
      " |  \n",
      " |  boxplot = boxplot_frame_groupby(grouped, subplots=True, column=None, fontsize=None, rot=0, grid=True, ax=None, figsize=None, layout=None, **kwds)\n",
      " |      Make box plots from DataFrameGroupBy data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      grouped : Grouped DataFrame\n",
      " |      subplots :\n",
      " |          * ``False`` - no subplots will be used\n",
      " |          * ``True`` - create a subplot for each group\n",
      " |      column : column name or list of names, or vector\n",
      " |          Can be any valid input to groupby\n",
      " |      fontsize : int or string\n",
      " |      rot : label rotation angle\n",
      " |      grid : Setting this to True will show the grid\n",
      " |      ax : Matplotlib axis object, default None\n",
      " |      figsize : A tuple (width, height) in inches\n",
      " |      layout : tuple (optional)\n",
      " |          (rows, columns) for the layout of the plot\n",
      " |      kwds : other plotting keyword arguments to be passed to matplotlib boxplot\n",
      " |             function\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict of key/value = group key/DataFrame.boxplot return value\n",
      " |      or DataFrame.boxplot return value in case subplots=figures=False\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas\n",
      " |      >>> import numpy as np\n",
      " |      >>> import itertools\n",
      " |      >>>\n",
      " |      >>> tuples = [t for t in itertools.product(range(1000), range(4))]\n",
      " |      >>> index = pandas.MultiIndex.from_tuples(tuples, names=['lvl0', 'lvl1'])\n",
      " |      >>> data = np.random.randn(len(index),4)\n",
      " |      >>> df = pandas.DataFrame(data, columns=list('ABCD'), index=index)\n",
      " |      >>>\n",
      " |      >>> grouped = df.groupby(level='lvl1')\n",
      " |      >>> boxplot_frame_groupby(grouped)\n",
      " |      >>>\n",
      " |      >>> grouped = df.unstack(level='lvl1').groupby(level=0, axis=1)\n",
      " |      >>> boxplot_frame_groupby(grouped, subplots=False)\n",
      " |  \n",
      " |  count(self)\n",
      " |      Compute count of group, excluding missing values\n",
      " |  \n",
      " |  nunique(self, dropna=True)\n",
      " |      Return DataFrame with number of distinct observations per group for\n",
      " |      each column.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include NaN in the counts.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nunique: DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'id': ['spam', 'egg', 'egg', 'spam',\n",
      " |      ...                           'ham', 'ham'],\n",
      " |      ...                    'value1': [1, 5, 5, 2, 5, 5],\n",
      " |      ...                    'value2': list('abbaxy')})\n",
      " |      >>> df\n",
      " |           id  value1 value2\n",
      " |      0  spam       1      a\n",
      " |      1   egg       5      b\n",
      " |      2   egg       5      b\n",
      " |      3  spam       2      a\n",
      " |      4   ham       5      x\n",
      " |      5   ham       5      y\n",
      " |      \n",
      " |      >>> df.groupby('id').nunique()\n",
      " |          id  value1  value2\n",
      " |      id\n",
      " |      egg    1       1       1\n",
      " |      ham    1       1       2\n",
      " |      spam   1       2       1\n",
      " |      \n",
      " |      # check for rows with the same id but conflicting values\n",
      " |      >>> df.groupby('id').filter(lambda g: (g.nunique() > 1).any())\n",
      " |           id  value1 value2\n",
      " |      0  spam       1      a\n",
      " |      3  spam       2      a\n",
      " |      4   ham       5      x\n",
      " |      5   ham       5      y\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  all\n",
      " |      \n",
      " |      Return whether all elements are True over requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      all : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  any\n",
      " |      \n",
      " |      Return whether any element is True over requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      any : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  corr\n",
      " |      Compute pairwise correlation of columns, excluding NA/null values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'pearson', 'kendall', 'spearman'}\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result. Currently only available for pearson\n",
      " |          and spearman correlation\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : DataFrame\n",
      " |  \n",
      " |  corrwith\n",
      " |      Compute pairwise correlation between rows or columns of two DataFrame\n",
      " |      objects.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' to compute column-wise, 1 or 'columns' for row-wise\n",
      " |      drop : boolean, default False\n",
      " |          Drop missing indices from result, default returns union of all\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      correls : Series\n",
      " |  \n",
      " |  cov\n",
      " |      Compute pairwise covariance of columns, excluding NA/null values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `y` contains the covariance matrix of the DataFrame's time series.\n",
      " |      The covariance is normalized by N-1 (unbiased estimator).\n",
      " |  \n",
      " |  diff\n",
      " |      1st discrete difference of object\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming difference\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Take difference over rows (0) or columns (1).\n",
      " |      \n",
      " |          .. versionadded: 0.16.1\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      diffed : DataFrame\n",
      " |  \n",
      " |  dtypes\n",
      " |      Return the dtypes in this object.\n",
      " |  \n",
      " |  fillna\n",
      " |      Fill NA/NaN values using the specified method\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame). (values not\n",
      " |          in the dict/Series/DataFrame will not be filled). This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use NEXT valid observation to fill gap\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |      inplace : boolean, default False\n",
      " |          If True, fill in place. Note: this will modify any\n",
      " |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          a dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex, asfreq\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : DataFrame\n",
      " |  \n",
      " |  hist\n",
      " |      Draw histogram of the DataFrame's series using matplotlib / pylab.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |      column : string or sequence\n",
      " |          If passed, will be used to limit data to a subset of columns\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups\n",
      " |      grid : boolean, default True\n",
      " |          Whether to show axis grid lines\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size\n",
      " |      xrot : float, default None\n",
      " |          rotation of x axis labels\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size\n",
      " |      yrot : float, default None\n",
      " |          rotation of y axis labels\n",
      " |      ax : matplotlib axes object, default None\n",
      " |      sharex : boolean, default True if ax is None else False\n",
      " |          In case subplots=True, share x axis and set some x axis labels to\n",
      " |          invisible; defaults to True if ax is None otherwise False if an ax\n",
      " |          is passed in; Be aware, that passing in both an ax and sharex=True\n",
      " |          will alter all x axis labels for all subplots in a figure!\n",
      " |      sharey : boolean, default False\n",
      " |          In case subplots=True, share y axis and set some y axis labels to\n",
      " |          invisible\n",
      " |      figsize : tuple\n",
      " |          The size of the figure to create in inches by default\n",
      " |      layout : tuple, optional\n",
      " |          Tuple of (rows, columns) for the layout of the histograms\n",
      " |      bins : integer, default 10\n",
      " |          Number of histogram bins to be used\n",
      " |      kwds : other plotting keyword arguments\n",
      " |          To be passed to hist function\n",
      " |  \n",
      " |  idxmax\n",
      " |      Return index of first occurrence of maximum over requested axis.\n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be first index.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Series\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmax\n",
      " |  \n",
      " |  idxmin\n",
      " |      Return index of first occurrence of minimum over requested axis.\n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Series\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmin\n",
      " |  \n",
      " |  mad\n",
      " |      \n",
      " |      Return the mean absolute deviation of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mad : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  pct_change\n",
      " |      Percent change over given number of periods.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change\n",
      " |      fill_method : str, default 'pad'\n",
      " |          How to handle NAs before computing percent changes\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping\n",
      " |      freq : DateOffset, timedelta, or offset alias string, optional\n",
      " |          Increment to use from time series API (e.g. 'M' or BDay())\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      chg : NDFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      By default, the percentage change is calculated along the stat\n",
      " |      axis: 0, or ``Index``, for ``DataFrame`` and 1, or ``minor`` for\n",
      " |      ``Panel``. You can change this with the ``axis`` keyword argument.\n",
      " |  \n",
      " |  quantile\n",
      " |      Return values at the given quantile over requested axis, a la\n",
      " |      numpy.percentile.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          0 <= q <= 1, the quantile(s) to compute\n",
      " |      axis : {0, 1, 'index', 'columns'} (default 0)\n",
      " |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |          * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |            fractional part of the index surrounded by `i` and `j`.\n",
      " |          * lower: `i`.\n",
      " |          * higher: `j`.\n",
      " |          * nearest: `i` or `j` whichever is nearest.\n",
      " |          * midpoint: (`i` + `j`) / 2.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      quantiles : Series or DataFrame\n",
      " |      \n",
      " |          - If ``q`` is an array, a DataFrame will be returned where the\n",
      " |            index is ``q``, the columns are the columns of self, and the\n",
      " |            values are the quantiles.\n",
      " |          - If ``q`` is a float, a Series will be returned where the\n",
      " |            index is the columns of self and the values are the quantiles.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n",
      " |                         columns=['a', 'b'])\n",
      " |      >>> df.quantile(.1)\n",
      " |      a    1.3\n",
      " |      b    3.7\n",
      " |      dtype: float64\n",
      " |      >>> df.quantile([.1, .5])\n",
      " |             a     b\n",
      " |      0.1  1.3   3.7\n",
      " |      0.5  2.5  55.0\n",
      " |  \n",
      " |  rank\n",
      " |      Compute numerical data ranks (1 through n) along axis. Equal values are\n",
      " |      assigned a rank that is the average of the ranks of those values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          index to direct ranking\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}\n",
      " |          * average: average rank of group\n",
      " |          * min: lowest rank in group\n",
      " |          * max: highest rank in group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. Valid only for DataFrame or\n",
      " |          Panel objects\n",
      " |      na_option : {'keep', 'top', 'bottom'}\n",
      " |          * keep: leave NA values where they are\n",
      " |          * top: smallest rank if ascending\n",
      " |          * bottom: smallest rank if descending\n",
      " |      ascending : boolean, default True\n",
      " |          False for ranks by high (1) to low (N)\n",
      " |      pct : boolean, default False\n",
      " |          Computes percentage rank of data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ranks : same type as caller\n",
      " |  \n",
      " |  skew\n",
      " |      \n",
      " |      Return unbiased skew over requested axis\n",
      " |      Normalized by N-1\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      skew : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  take\n",
      " |      Analogous to ndarray.take\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : list / array of ints\n",
      " |      axis : int, default 0\n",
      " |      convert : translate neg to pos indices (default)\n",
      " |      is_copy : mark the returned frame as a copy\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : type of caller\n",
      " |  \n",
      " |  tshift\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, default None\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM')\n",
      " |      axis : int or basestring\n",
      " |          Corresponds to the axis that contains the Index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : NDFrame\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from NDFrameGroupBy:\n",
      " |  \n",
      " |  filter(self, func, dropna=True, *args, **kwargs)\n",
      " |      Return a copy of a DataFrame excluding elements from groups that\n",
      " |      do not satisfy the boolean criterion specified by func.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      f : function\n",
      " |          Function to apply to each subframe. Should return True or False.\n",
      " |      dropna : Drop groups that do not pass the filter. True by default;\n",
      " |          if False, groups that evaluate False are filled with NaNs.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Each subframe is endowed the attribute 'name' in case you need to know\n",
      " |      which group you are working on.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      " |      ...                           'foo', 'bar'],\n",
      " |      ...                    'B' : [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'C' : [2.0, 5., 8., 1., 2., 9.]})\n",
      " |      >>> grouped = df.groupby('A')\n",
      " |      >>> grouped.filter(lambda x: x['B'].mean() > 3.)\n",
      " |           A  B    C\n",
      " |      1  bar  2  5.0\n",
      " |      3  bar  4  1.0\n",
      " |      5  bar  6  9.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filtered : DataFrame\n",
      " |  \n",
      " |  transform(self, func, *args, **kwargs)\n",
      " |      Call function producing a like-indexed DataFrame on each group and\n",
      " |      return a DataFrame having the same indexes as the original object\n",
      " |      filled with the transformed values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      f : function\n",
      " |          Function to apply to each group\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Each group is endowed the attribute 'name' in case you need to know\n",
      " |      which group you are working on.\n",
      " |      \n",
      " |      The current implementation imposes three requirements on f:\n",
      " |      \n",
      " |      * f must return a value that either has the same shape as the input\n",
      " |        subframe or can be broadcast to the shape of the input subframe.\n",
      " |        For example, f returns a scalar it will be broadcast to have the\n",
      " |        same shape as the input subframe.\n",
      " |      * if this is a DataFrame, f must support application column-by-column\n",
      " |        in the subframe. If f also supports application to the entire subframe,\n",
      " |        then a fast path is used starting from the second chunk.\n",
      " |      * f must not mutate groups. Mutation is not supported and may\n",
      " |        produce unexpected results.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      aggregate, transform\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      # Same shape\n",
      " |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      " |      ...                           'foo', 'bar'],\n",
      " |      ...                    'B' : ['one', 'one', 'two', 'three',\n",
      " |      ...                          'two', 'two'],\n",
      " |      ...                    'C' : [1, 5, 5, 2, 5, 5],\n",
      " |      ...                    'D' : [2.0, 5., 8., 1., 2., 9.]})\n",
      " |      >>> grouped = df.groupby('A')\n",
      " |      >>> grouped.transform(lambda x: (x - x.mean()) / x.std())\n",
      " |                C         D\n",
      " |      0 -1.154701 -0.577350\n",
      " |      1  0.577350  0.000000\n",
      " |      2  0.577350  1.154701\n",
      " |      3 -1.154701 -1.000000\n",
      " |      4  0.577350 -0.577350\n",
      " |      5  0.577350  1.000000\n",
      " |      \n",
      " |      # Broadcastable\n",
      " |      >>> grouped.transform(lambda x: x.max() - x.min())\n",
      " |         C    D\n",
      " |      0  4  6.0\n",
      " |      1  3  8.0\n",
      " |      2  4  6.0\n",
      " |      3  3  8.0\n",
      " |      4  4  6.0\n",
      " |      5  3  8.0\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from GroupBy:\n",
      " |  \n",
      " |  backfill(self, limit=None)\n",
      " |      Backward fill the values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : integer, optional\n",
      " |          limit of how many values to fill\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.fillna\n",
      " |      DataFrame.fillna\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  bfill = backfill(self, limit=None)\n",
      " |      Backward fill the values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : integer, optional\n",
      " |          limit of how many values to fill\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.fillna\n",
      " |      DataFrame.fillna\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cumcount(self, ascending=True)\n",
      " |      Number each item in each group from 0 to the length of that group - 1.\n",
      " |      \n",
      " |      Essentially this is equivalent to\n",
      " |      \n",
      " |      >>> self.apply(lambda x: Series(np.arange(len(x)), x.index))\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : bool, default True\n",
      " |          If False, number in reverse, from length of group - 1 to 0.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],\n",
      " |      ...                   columns=['A'])\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  a\n",
      " |      1  a\n",
      " |      2  a\n",
      " |      3  b\n",
      " |      4  b\n",
      " |      5  a\n",
      " |      >>> df.groupby('A').cumcount()\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    0\n",
      " |      4    1\n",
      " |      5    3\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby('A').cumcount(ascending=False)\n",
      " |      0    3\n",
      " |      1    2\n",
      " |      2    1\n",
      " |      3    1\n",
      " |      4    0\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      .ngroup : Number the groups themselves.\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cummax(self, axis=0, **kwargs)\n",
      " |      Cumulative max for each group\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cummin(self, axis=0, **kwargs)\n",
      " |      Cumulative min for each group\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cumprod(self, axis=0, *args, **kwargs)\n",
      " |      Cumulative product for each group\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cumsum(self, axis=0, *args, **kwargs)\n",
      " |      Cumulative sum for each group\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  describe(self, **kwargs)\n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |      \n",
      " |              Generates descriptive statistics that summarize the central tendency,\n",
      " |              dispersion and shape of a dataset's distribution, excluding\n",
      " |              ``NaN`` values.\n",
      " |      \n",
      " |              Analyzes both numeric and object series, as well\n",
      " |              as ``DataFrame`` column sets of mixed data types. The output\n",
      " |              will vary depending on what is provided. Refer to the notes\n",
      " |              below for more detail.\n",
      " |      \n",
      " |              Parameters\n",
      " |              ----------\n",
      " |              percentiles : list-like of numbers, optional\n",
      " |                  The percentiles to include in the output. All should\n",
      " |                  fall between 0 and 1. The default is\n",
      " |                  ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |                  75th percentiles.\n",
      " |              include : 'all', list-like of dtypes or None (default), optional\n",
      " |                  A white list of data types to include in the result. Ignored\n",
      " |                  for ``Series``. Here are the options:\n",
      " |      \n",
      " |                  - 'all' : All columns of the input will be included in the output.\n",
      " |                  - A list-like of dtypes : Limits the results to the\n",
      " |                    provided data types.\n",
      " |                    To limit the result to numeric types submit\n",
      " |                    ``numpy.number``. To limit it instead to categorical\n",
      " |                    objects submit the ``numpy.object`` data type. Strings\n",
      " |                    can also be used in the style of\n",
      " |                    ``select_dtypes`` (e.g. ``df.describe(include=['O'])``)\n",
      " |                  - None (default) : The result will include all numeric columns.\n",
      " |              exclude : list-like of dtypes or None (default), optional,\n",
      " |                  A black list of data types to omit from the result. Ignored\n",
      " |                  for ``Series``. Here are the options:\n",
      " |      \n",
      " |                  - A list-like of dtypes : Excludes the provided data types\n",
      " |                    from the result. To select numeric types submit\n",
      " |                    ``numpy.number``. To select categorical objects submit the data\n",
      " |                    type ``numpy.object``. Strings can also be used in the style of\n",
      " |                    ``select_dtypes`` (e.g. ``df.describe(include=['O'])``)\n",
      " |                  - None (default) : The result will exclude nothing.\n",
      " |      \n",
      " |              Returns\n",
      " |              -------\n",
      " |              summary:  Series/DataFrame of summary statistics\n",
      " |      \n",
      " |              Notes\n",
      " |              -----\n",
      " |              For numeric data, the result's index will include ``count``,\n",
      " |              ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |              upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |              upper percentile is ``75``. The ``50`` percentile is the\n",
      " |              same as the median.\n",
      " |      \n",
      " |              For object data (e.g. strings or timestamps), the result's index\n",
      " |              will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |              is the most common value. The ``freq`` is the most common value's\n",
      " |              frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |              If multiple object values have the highest count, then the\n",
      " |              ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |              among those with the highest count.\n",
      " |      \n",
      " |              For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |              return only an analysis of numeric columns. If ``include='all'``\n",
      " |              is provided as an option, the result will include a union of\n",
      " |              attributes of each type.\n",
      " |      \n",
      " |              The `include` and `exclude` parameters can be used to limit\n",
      " |              which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |              The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |              Examples\n",
      " |              --------\n",
      " |              Describing a numeric ``Series``.\n",
      " |      \n",
      " |              >>> s = pd.Series([1, 2, 3])\n",
      " |              >>> s.describe()\n",
      " |              count    3.0\n",
      " |              mean     2.0\n",
      " |              std      1.0\n",
      " |              min      1.0\n",
      " |              25%      1.5\n",
      " |              50%      2.0\n",
      " |              75%      2.5\n",
      " |              max      3.0\n",
      " |      \n",
      " |              Describing a categorical ``Series``.\n",
      " |      \n",
      " |              >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |              >>> s.describe()\n",
      " |              count     4\n",
      " |              unique    3\n",
      " |              top       a\n",
      " |              freq      2\n",
      " |              dtype: object\n",
      " |      \n",
      " |              Describing a timestamp ``Series``.\n",
      " |      \n",
      " |              >>> s = pd.Series([\n",
      " |              ...   np.datetime64(\"2000-01-01\"),\n",
      " |              ...   np.datetime64(\"2010-01-01\"),\n",
      " |              ...   np.datetime64(\"2010-01-01\")\n",
      " |              ... ])\n",
      " |              >>> s.describe()\n",
      " |              count                       3\n",
      " |              unique                      2\n",
      " |              top       2010-01-01 00:00:00\n",
      " |              freq                        2\n",
      " |              first     2000-01-01 00:00:00\n",
      " |              last      2010-01-01 00:00:00\n",
      " |              dtype: object\n",
      " |      \n",
      " |              Describing a ``DataFrame``. By default only numeric fields\n",
      " |              are returned.\n",
      " |      \n",
      " |              >>> df = pd.DataFrame([[1, 'a'], [2, 'b'], [3, 'c']],\n",
      " |              ...                   columns=['numeric', 'object'])\n",
      " |              >>> df.describe()\n",
      " |                     numeric\n",
      " |              count      3.0\n",
      " |              mean       2.0\n",
      " |              std        1.0\n",
      " |              min        1.0\n",
      " |              25%        1.5\n",
      " |              50%        2.0\n",
      " |              75%        2.5\n",
      " |              max        3.0\n",
      " |      \n",
      " |              Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |              >>> df.describe(include='all')\n",
      " |                      numeric object\n",
      " |              count       3.0      3\n",
      " |              unique      NaN      3\n",
      " |              top         NaN      b\n",
      " |              freq        NaN      1\n",
      " |              mean        2.0    NaN\n",
      " |              std         1.0    NaN\n",
      " |              min         1.0    NaN\n",
      " |              25%         1.5    NaN\n",
      " |              50%         2.0    NaN\n",
      " |              75%         2.5    NaN\n",
      " |              max         3.0    NaN\n",
      " |      \n",
      " |              Describing a column from a ``DataFrame`` by accessing it as\n",
      " |              an attribute.\n",
      " |      \n",
      " |              >>> df.numeric.describe()\n",
      " |              count    3.0\n",
      " |              mean     2.0\n",
      " |              std      1.0\n",
      " |              min      1.0\n",
      " |              25%      1.5\n",
      " |              50%      2.0\n",
      " |              75%      2.5\n",
      " |              max      3.0\n",
      " |              Name: numeric, dtype: float64\n",
      " |      \n",
      " |              Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |              >>> df.describe(include=[np.number])\n",
      " |                     numeric\n",
      " |              count      3.0\n",
      " |              mean       2.0\n",
      " |              std        1.0\n",
      " |              min        1.0\n",
      " |              25%        1.5\n",
      " |              50%        2.0\n",
      " |              75%        2.5\n",
      " |              max        3.0\n",
      " |      \n",
      " |              Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |              >>> df.describe(include=[np.object])\n",
      " |                     object\n",
      " |              count       3\n",
      " |              unique      3\n",
      " |              top         b\n",
      " |              freq        1\n",
      " |      \n",
      " |              Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |              >>> df.describe(exclude=[np.number])\n",
      " |                     object\n",
      " |              count       3\n",
      " |              unique      3\n",
      " |              top         b\n",
      " |              freq        1\n",
      " |      \n",
      " |              Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |              >>> df.describe(exclude=[np.object])\n",
      " |                     numeric\n",
      " |              count      3.0\n",
      " |              mean       2.0\n",
      " |              std        1.0\n",
      " |              min        1.0\n",
      " |              25%        1.5\n",
      " |              50%        2.0\n",
      " |              75%        2.5\n",
      " |              max        3.0\n",
      " |      \n",
      " |              See Also\n",
      " |              --------\n",
      " |              DataFrame.count\n",
      " |              DataFrame.max\n",
      " |              DataFrame.min\n",
      " |              DataFrame.mean\n",
      " |              DataFrame.std\n",
      " |              DataFrame.select_dtypes\n",
      " |  \n",
      " |  expanding(self, *args, **kwargs)\n",
      " |      Return an expanding grouper, providing expanding\n",
      " |      functionaility per group\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ffill = pad(self, limit=None)\n",
      " |      Forward fill the values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : integer, optional\n",
      " |          limit of how many values to fill\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.fillna\n",
      " |      DataFrame.fillna\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  first(self, **kwargs)\n",
      " |      Compute first of group values\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  head(self, n=5)\n",
      " |      Returns first n rows of each group.\n",
      " |      \n",
      " |      Essentially equivalent to ``.apply(lambda x: x.head(n))``,\n",
      " |      except ignores as_index flag.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame([[1, 2], [1, 4], [5, 6]],\n",
      " |                         columns=['A', 'B'])\n",
      " |      >>> df.groupby('A', as_index=False).head(1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      2  5  6\n",
      " |      >>> df.groupby('A').head(1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      2  5  6\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  last(self, **kwargs)\n",
      " |      Compute last of group values\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  max(self, **kwargs)\n",
      " |      Compute max of group values\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  mean(self, *args, **kwargs)\n",
      " |      Compute mean of groups, excluding missing values\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  median(self, **kwargs)\n",
      " |      Compute median of groups, excluding missing values\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  min(self, **kwargs)\n",
      " |      Compute min of group values\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ngroup(self, ascending=True)\n",
      " |      Number each group from 0 to the number of groups - 1.\n",
      " |      \n",
      " |      This is the enumerative complement of cumcount.  Note that the\n",
      " |      numbers given to the groups match the order in which the groups\n",
      " |      would be seen when iterating over the groupby object, not the\n",
      " |      order they are first observed.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.2\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : bool, default True\n",
      " |          If False, number in reverse, from number of group - 1 to 0.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": list(\"aaabba\")})\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  a\n",
      " |      1  a\n",
      " |      2  a\n",
      " |      3  b\n",
      " |      4  b\n",
      " |      5  a\n",
      " |      >>> df.groupby('A').ngroup()\n",
      " |      0    0\n",
      " |      1    0\n",
      " |      2    0\n",
      " |      3    1\n",
      " |      4    1\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby('A').ngroup(ascending=False)\n",
      " |      0    1\n",
      " |      1    1\n",
      " |      2    1\n",
      " |      3    0\n",
      " |      4    0\n",
      " |      5    1\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby([\"A\", [1,1,2,3,2,1]]).ngroup()\n",
      " |      0    0\n",
      " |      1    0\n",
      " |      2    1\n",
      " |      3    3\n",
      " |      4    2\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      .cumcount : Number the rows in each group.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  nth(self, n, dropna=None)\n",
      " |      Take the nth row from each group if n is an int, or a subset of rows\n",
      " |      if n is a list of ints.\n",
      " |      \n",
      " |      If dropna, will take the nth non-null row, dropna is either\n",
      " |      Truthy (if a Series) or 'all', 'any' (if a DataFrame);\n",
      " |      this is equivalent to calling dropna(how=dropna) before the\n",
      " |      groupby.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int or list of ints\n",
      " |          a single nth value for the row or a list of nth values\n",
      " |      dropna : None or str, optional\n",
      " |          apply the specified dropna operation before counting which row is\n",
      " |          the nth row. Needs to be None, 'any' or 'all'\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      " |      ...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])\n",
      " |      >>> g = df.groupby('A')\n",
      " |      >>> g.nth(0)\n",
      " |           B\n",
      " |      A\n",
      " |      1  NaN\n",
      " |      2  3.0\n",
      " |      >>> g.nth(1)\n",
      " |           B\n",
      " |      A\n",
      " |      1  2.0\n",
      " |      2  5.0\n",
      " |      >>> g.nth(-1)\n",
      " |           B\n",
      " |      A\n",
      " |      1  4.0\n",
      " |      2  5.0\n",
      " |      >>> g.nth([0, 1])\n",
      " |           B\n",
      " |      A\n",
      " |      1  NaN\n",
      " |      1  2.0\n",
      " |      2  3.0\n",
      " |      2  5.0\n",
      " |      \n",
      " |      Specifying ``dropna`` allows count ignoring NaN\n",
      " |      \n",
      " |      >>> g.nth(0, dropna='any')\n",
      " |           B\n",
      " |      A\n",
      " |      1  2.0\n",
      " |      2  3.0\n",
      " |      \n",
      " |      NaNs denote group exhausted when using dropna\n",
      " |      \n",
      " |      >>> g.nth(3, dropna='any')\n",
      " |          B\n",
      " |      A\n",
      " |      1 NaN\n",
      " |      2 NaN\n",
      " |      \n",
      " |      Specifying ``as_index=False`` in ``groupby`` keeps the original index.\n",
      " |      \n",
      " |      >>> df.groupby('A', as_index=False).nth(1)\n",
      " |         A    B\n",
      " |      1  1  2.0\n",
      " |      4  2  5.0\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ohlc(self)\n",
      " |      Compute sum of values, excluding missing values\n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  pad(self, limit=None)\n",
      " |      Forward fill the values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : integer, optional\n",
      " |          limit of how many values to fill\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.fillna\n",
      " |      DataFrame.fillna\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  prod(self, **kwargs)\n",
      " |      Compute prod of group values\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  resample(self, rule, *args, **kwargs)\n",
      " |      Provide resampling when using a TimeGrouper\n",
      " |      Return a new grouper with our resampler appended\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  rolling(self, *args, **kwargs)\n",
      " |      Return a rolling grouper, providing rolling\n",
      " |      functionaility per group\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  sem(self, ddof=1)\n",
      " |      Compute standard error of the mean of groups, excluding missing values\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : integer, default 1\n",
      " |          degrees of freedom\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift each group by periods observations\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : integer, default 1\n",
      " |          number of periods to shift\n",
      " |      freq : frequency string\n",
      " |      axis : axis to shift, default 0\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  size(self)\n",
      " |      Compute group sizes\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  std(self, ddof=1, *args, **kwargs)\n",
      " |      Compute standard deviation of groups, excluding missing values\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : integer, default 1\n",
      " |          degrees of freedom\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  sum(self, **kwargs)\n",
      " |      Compute sum of group values\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  tail(self, n=5)\n",
      " |      Returns last n rows of each group\n",
      " |      \n",
      " |      Essentially equivalent to ``.apply(lambda x: x.tail(n))``,\n",
      " |      except ignores as_index flag.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],\n",
      " |                         columns=['A', 'B'])\n",
      " |      >>> df.groupby('A').tail(1)\n",
      " |         A  B\n",
      " |      1  a  2\n",
      " |      3  b  2\n",
      " |      >>> df.groupby('A').head(1)\n",
      " |         A  B\n",
      " |      0  a  1\n",
      " |      2  b  1\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  var(self, ddof=1, *args, **kwargs)\n",
      " |      Compute variance of groups, excluding missing values\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : integer, default 1\n",
      " |          degrees of freedom\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _GroupBy:\n",
      " |  \n",
      " |  __getattr__(self, attr)\n",
      " |  \n",
      " |  __init__(self, obj, keys=None, axis=0, level=None, grouper=None, exclusions=None, selection=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Groupby iterator\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Generator yielding sequence of (name, subsetted object)\n",
      " |      for each group\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by unicode(obj) in py2 only. Yields a Unicode String in both\n",
      " |      py2/py3.\n",
      " |  \n",
      " |  apply(self, func, *args, **kwargs)\n",
      " |      Apply function and combine results together in an intelligent way. The\n",
      " |      split-apply-combine combination rules attempt to be as common sense\n",
      " |      based as possible. For example:\n",
      " |      \n",
      " |      case 1:\n",
      " |      group DataFrame\n",
      " |      apply aggregation function (f(chunk) -> Series)\n",
      " |      yield DataFrame, with group axis having group labels\n",
      " |      \n",
      " |      case 2:\n",
      " |      group DataFrame\n",
      " |      apply transform function ((f(chunk) -> DataFrame with same indexes)\n",
      " |      yield DataFrame with resulting chunks glued together\n",
      " |      \n",
      " |      case 3:\n",
      " |      group Series\n",
      " |      apply function with f(chunk) -> DataFrame\n",
      " |      yield DataFrame with result of chunks glued together\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See online documentation for full exposition on how to use apply.\n",
      " |      \n",
      " |      In the current implementation apply calls func twice on the\n",
      " |      first group to decide whether it can take a fast or slow code\n",
      " |      path. This can lead to unexpected behavior if func has\n",
      " |      side-effects, as they will take effect twice for the first\n",
      " |      group.\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      aggregate, transform\n",
      " |  \n",
      " |  get_group(self, name, obj=None)\n",
      " |      Constructs NDFrame from group with provided name\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : object\n",
      " |          the name of the group to get as a DataFrame\n",
      " |      obj : NDFrame, default None\n",
      " |          the NDFrame to take the DataFrame out of.  If\n",
      " |          it is None, the object groupby was called on will\n",
      " |          be used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      group : type of obj\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _GroupBy:\n",
      " |  \n",
      " |  groups\n",
      " |      dict {group name -> group labels}\n",
      " |  \n",
      " |  indices\n",
      " |      dict {group name -> group indices}\n",
      " |  \n",
      " |  ngroups\n",
      " |  \n",
      " |  plot\n",
      " |      Class implementing the .plot attribute for groupby objects\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion\n",
      " |      Only provide 'public' methods\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Generates the total memory usage for a object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __bytes__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by bytes(obj) in py3 only.\n",
      " |      Yields a bytestring in both py2/py3.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a string representation for a particular Object\n",
      " |      \n",
      " |      Invoked by str(df) in both py2/py3.\n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.SelectionMixin:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.SelectionMixin:\n",
      " |  \n",
      " |  ndim\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(result.groupby('Movie ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchs = result.groupby('Movie ID').agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         User ID Rating Rating Timestamp Movie Title Genre\n",
      "           count  count            count       count count\n",
      "Movie ID                                                  \n",
      "131            1      1                1           1     1\n",
      "417           22     22               22          22    22\n",
      "2354           1      1                1           1     1\n",
      "3863           1      1                1           1     1\n",
      "4099           2      2                2           2     2\n"
     ]
    }
   ],
   "source": [
    "print(watchs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchs2 = watchs['Rating']['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie ID\n",
      "131      1\n",
      "417     22\n",
      "2354     1\n",
      "3863     1\n",
      "4099     2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(watchs2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          User ID  Rating  Rating Timestamp\n",
      "Movie ID                                   \n",
      "7134690   30110.0    10.0      1.524974e+09\n",
      "3799996    2139.0    10.0      1.431606e+09\n",
      "2381958   31836.0    10.0      1.395280e+09\n",
      "2380390   37135.0    10.0      1.410507e+09\n",
      "2379090   33877.0    10.0      1.372359e+09\n"
     ]
    }
   ],
   "source": [
    "print(bests.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 满分电影中，按照观看次数排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([7134690, 3799996, 2381958, 2380390, 2379090,  110852, 2377194,\n",
       "            2375037,   45907, 2374002,\n",
       "            ...\n",
       "              50263, 4612116, 8242160,   75793, 1747960,   75744,   50818,\n",
       "             184512, 1737122,   24316],\n",
       "           dtype='int64', name='Movie ID', length=501)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bests.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     131,      417,     2354,     3863,     4099,     4100,\n",
       "                4101,     4210,     4395,     4518,\n",
       "            ...\n",
       "            10726756, 10737904, 10810424, 10847194, 10847306, 10847330,\n",
       "            10895830, 10952752, 10971520, 10977680],\n",
       "           dtype='int64', name='Movie ID', length=10740)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watchs2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rating Timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Movie ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7134690</th>\n",
       "      <td>30110.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.524974e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          User ID  Rating  Rating Timestamp\n",
       "Movie ID                                   \n",
       "7134690   30110.0    10.0      1.524974e+09"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bests[bests.index==7134690]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Movie ID\n",
       "7134690    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watchs2[watchs2.index==7134690]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bests_most = bests.join(watchs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rating Timestamp</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Movie ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4921860</th>\n",
       "      <td>36898.187500</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.445855e+09</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5262972</th>\n",
       "      <td>29330.607143</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.452208e+09</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6662050</th>\n",
       "      <td>22627.409091</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.555754e+09</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448444</th>\n",
       "      <td>29148.600000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.484094e+09</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254364</th>\n",
       "      <td>33191.750000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.393409e+09</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107858</th>\n",
       "      <td>40613.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.458871e+09</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974050</th>\n",
       "      <td>26035.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.494164e+09</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467380</th>\n",
       "      <td>21917.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.487992e+09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69847</th>\n",
       "      <td>31107.666667</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.381879e+09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865561</th>\n",
       "      <td>17248.333333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.370224e+09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375037</th>\n",
       "      <td>45014.666667</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.370802e+09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3640822</th>\n",
       "      <td>23716.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.417384e+09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158446</th>\n",
       "      <td>23608.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.456612e+09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33867</th>\n",
       "      <td>35914.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.375305e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23251</th>\n",
       "      <td>46840.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.385833e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25641</th>\n",
       "      <td>14082.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.411103e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23613</th>\n",
       "      <td>19906.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.392710e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45708</th>\n",
       "      <td>20185.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.431008e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107080</th>\n",
       "      <td>29255.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.454909e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210258</th>\n",
       "      <td>32577.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.468245e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648201</th>\n",
       "      <td>20337.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.372987e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109129</th>\n",
       "      <td>34373.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.455138e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69841</th>\n",
       "      <td>49961.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.376697e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57449</th>\n",
       "      <td>3031.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.420186e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306308</th>\n",
       "      <td>34340.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.423580e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257092</th>\n",
       "      <td>38079.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.531360e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791504</th>\n",
       "      <td>44470.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.396701e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6907804</th>\n",
       "      <td>29319.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.514906e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82926</th>\n",
       "      <td>32277.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.446688e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500906</th>\n",
       "      <td>49961.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.387768e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97116</th>\n",
       "      <td>49702.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.371185e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43286</th>\n",
       "      <td>48240.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.394940e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93215</th>\n",
       "      <td>10566.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.514767e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3450290</th>\n",
       "      <td>43546.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.402650e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116248</th>\n",
       "      <td>11068.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.376806e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125066</th>\n",
       "      <td>50170.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.404855e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40795</th>\n",
       "      <td>56723.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.378363e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142764</th>\n",
       "      <td>58311.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.397653e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95875</th>\n",
       "      <td>27820.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.455172e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93011</th>\n",
       "      <td>46264.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.392123e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401190</th>\n",
       "      <td>59609.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.403980e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42634</th>\n",
       "      <td>27820.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.364188e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93200</th>\n",
       "      <td>3954.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.393094e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093732</th>\n",
       "      <td>58361.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.491098e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3176074</th>\n",
       "      <td>58816.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.403759e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181128</th>\n",
       "      <td>2371.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.379112e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477982</th>\n",
       "      <td>25284.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.410724e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181962</th>\n",
       "      <td>51971.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.379571e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93228</th>\n",
       "      <td>9045.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.380218e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41509</th>\n",
       "      <td>34166.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.387140e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93596</th>\n",
       "      <td>31251.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.405829e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94364</th>\n",
       "      <td>41270.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.398396e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314696</th>\n",
       "      <td>29443.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.389040e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41671</th>\n",
       "      <td>7367.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.380810e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241906</th>\n",
       "      <td>22361.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.390991e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41718</th>\n",
       "      <td>48240.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.371125e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3302654</th>\n",
       "      <td>6103.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.516494e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179372</th>\n",
       "      <td>43188.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.458096e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469386</th>\n",
       "      <td>34700.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.402351e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24316</th>\n",
       "      <td>5268.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.397506e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               User ID  Rating  Rating Timestamp  count\n",
       "Movie ID                                               \n",
       "4921860   36898.187500    10.0      1.445855e+09     48\n",
       "5262972   29330.607143    10.0      1.452208e+09     28\n",
       "6662050   22627.409091    10.0      1.555754e+09     22\n",
       "4448444   29148.600000    10.0      1.484094e+09      5\n",
       "2254364   33191.750000    10.0      1.393409e+09      4\n",
       "4107858   40613.500000    10.0      1.458871e+09      4\n",
       "2974050   26035.500000    10.0      1.494164e+09      4\n",
       "6467380   21917.000000    10.0      1.487992e+09      3\n",
       "69847     31107.666667    10.0      1.381879e+09      3\n",
       "865561    17248.333333    10.0      1.370224e+09      3\n",
       "2375037   45014.666667    10.0      1.370802e+09      3\n",
       "3640822   23716.000000    10.0      1.417384e+09      3\n",
       "158446    23608.000000    10.0      1.456612e+09      3\n",
       "33867     35914.500000    10.0      1.375305e+09      2\n",
       "23251     46840.500000    10.0      1.385833e+09      2\n",
       "25641     14082.000000    10.0      1.411103e+09      2\n",
       "23613     19906.000000    10.0      1.392710e+09      2\n",
       "45708     20185.500000    10.0      1.431008e+09      2\n",
       "107080    29255.000000    10.0      1.454909e+09      2\n",
       "3210258   32577.500000    10.0      1.468245e+09      2\n",
       "1648201   20337.000000    10.0      1.372987e+09      2\n",
       "109129    34373.500000    10.0      1.455138e+09      2\n",
       "69841     49961.000000    10.0      1.376697e+09      2\n",
       "57449      3031.500000    10.0      1.420186e+09      2\n",
       "4306308   34340.000000    10.0      1.423580e+09      2\n",
       "3257092   38079.500000    10.0      1.531360e+09      2\n",
       "1791504   44470.500000    10.0      1.396701e+09      2\n",
       "6907804   29319.000000    10.0      1.514906e+09      2\n",
       "82926     32277.500000    10.0      1.446688e+09      2\n",
       "1500906   49961.000000    10.0      1.387768e+09      2\n",
       "...                ...     ...               ...    ...\n",
       "97116     49702.000000    10.0      1.371185e+09      1\n",
       "43286     48240.000000    10.0      1.394940e+09      1\n",
       "93215     10566.000000    10.0      1.514767e+09      1\n",
       "3450290   43546.000000    10.0      1.402650e+09      1\n",
       "3116248   11068.000000    10.0      1.376806e+09      1\n",
       "3125066   50170.000000    10.0      1.404855e+09      1\n",
       "40795     56723.000000    10.0      1.378363e+09      1\n",
       "3142764   58311.000000    10.0      1.397653e+09      1\n",
       "95875     27820.000000    10.0      1.455172e+09      1\n",
       "93011     46264.000000    10.0      1.392123e+09      1\n",
       "3401190   59609.000000    10.0      1.403980e+09      1\n",
       "42634     27820.000000    10.0      1.364188e+09      1\n",
       "93200      3954.000000    10.0      1.393094e+09      1\n",
       "3093732   58361.000000    10.0      1.491098e+09      1\n",
       "3176074   58816.000000    10.0      1.403759e+09      1\n",
       "3181128    2371.000000    10.0      1.379112e+09      1\n",
       "3477982   25284.000000    10.0      1.410724e+09      1\n",
       "3181962   51971.000000    10.0      1.379571e+09      1\n",
       "93228      9045.000000    10.0      1.380218e+09      1\n",
       "41509     34166.000000    10.0      1.387140e+09      1\n",
       "93596     31251.000000    10.0      1.405829e+09      1\n",
       "94364     41270.000000    10.0      1.398396e+09      1\n",
       "3314696   29443.000000    10.0      1.389040e+09      1\n",
       "41671      7367.000000    10.0      1.380810e+09      1\n",
       "3241906   22361.000000    10.0      1.390991e+09      1\n",
       "41718     48240.000000    10.0      1.371125e+09      1\n",
       "3302654    6103.000000    10.0      1.516494e+09      1\n",
       "3179372   43188.000000    10.0      1.458096e+09      1\n",
       "3469386   34700.000000    10.0      1.402351e+09      1\n",
       "24316      5268.000000    10.0      1.397506e+09      1\n",
       "\n",
       "[501 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bests_most.sort_values(by='count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie ID</th>\n",
       "      <th>Movie Title</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30004</th>\n",
       "      <td>4921860</td>\n",
       "      <td>MSG 2 the Messenger (2015)</td>\n",
       "      <td>Comedy|Drama|Fantasy|Horror</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Movie ID                 Movie Title                        Genre\n",
       "30004   4921860  MSG 2 the Messenger (2015)  Comedy|Drama|Fantasy|Horror"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies[movies['Movie ID'] == 4921860]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
